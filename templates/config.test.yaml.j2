# This file can update the JupyterHub Helm chart's default configuration values.
#
# For reference see the configuration reference and default values, but make
# sure to refer to the Helm chart version of interest to you!
#
# Introduction to YAML:     https://www.youtube.com/watch?v=cdLNKUoMc6c
# Chart config reference:   https://zero-to-jupyterhub.readthedocs.io/en/stable/resources/reference.html
# Chart default values:     https://github.com/jupyterhub/zero-to-jupyterhub-k8s/blob/HEAD/jupyterhub/values.yaml
# Available chart versions: https://jupyterhub.github.io/helm-chart/
#
# Google is not currently supported
#
# If you update this file directly and want to redeploy via helm:
#
#    helm upgrade -f /opt/jupyterhub/config.yaml jupyterhub jupyterhub/jupyterhub
hub:
{% if JH_RESOURCES_REQUEST_CPU is defined or JH_RESOURCES_REQUEST_MEMORY is defined %}
  resources:
    requests:
{% if JH_RESOURCES_REQUEST_CPU is defined %}
      cpu: {{ JH_RESOURCES_REQUEST_CPU }}
{% endif %}
{% if JH_RESOURCES_REQUEST_MEMORY is defined %}
      memory: {{ JH_RESOURCES_REQUEST_MEMORY }}
{% endif %}
{% endif %}
{% if JH_DB_PVC_STORAGE_CLASS_NAME is defined %}
  db:
    pvc:
      storageClassName: "{{ JH_DB_PVC_STORAGE_CLASS_NAME }}"
{% endif %}
  config:
    JupyterHub:
# this could be useful later for forcing matching to specific nodes
#      scheduling:
#        corePods:
#          nodeAffinity:
#            # matchNodePurpose valid options:
#            # - ignore
#            # - prefer (the default)
#            # - require
#            matchNodePurpose: require
{% if JH_AUTH_CLASS != "default" %}
      authenticator_class: {{ JH_AUTH_CLASS }}
{% endif %}
    Authenticator:
{% if JH_ADMINS is defined %}
       admin_users:
{% for user in JH_ADMINS %}
       - {{ user }}
{% endfor %}
{% endif %}
{% if JH_ALLOWED_USERS is defined %}
       allowed_users:
{% for user in JH_ALLOWED_USERS %}
       - {{ user }}
{% endfor %}
{% endif %}
{% if JH_AUTH_CLASS == "github" %}
    GitHubOAuthenticator:
      client_id: "{{ JH_OAUTH2_CLIENT_ID }}"
      client_secret: "{{ JH_OAUTH2_CLIENT_SECRET }}"
      oauth_callback_url: {{ JH_OAUTH2_CALLBACK_URL }}
{% elif JH_AUTH_CLASS == "dummy" %}
    DummyAuthenticator:
      password: "{{ JH_DUMMY_PASS }}"
{% else %}
{% endif %}
  extraConfig:
    cyverse_config.py: |
      c.Spawner.http_timeout  = {{ JH_SINGLEUSER_HTTP_TIMEOUT }}
singleuser:
  defaultUrl: "{{ JH_SINGLEUSER_DEFAULT_URL }}"
  startTimeout: {{ JH_SINGLEUSER_START_TIMEOUT }}
  image:
    name: {{ JH_SINGLEUSER_IMAGE }}
    tag:  "{{ JH_SINGLEUSER_IMAGE_TAG | string }}"
  memory:
    guarantee: "{{ JH_SINGLEUSER_MEMORY_GUARANTEE }}"
{% if JH_SINGLEUSER_MEMORY_LIMIT is defined %}
    limit: "{{ JH_SINGLEUSER_MEMORY_LIMIT }}"
{% endif %}
  cpu:
    guarantee: {{ JH_SINGLEUSER_CPU_GUARANTEE }}
{% if JH_SINGLEUSER_CPU_LIMIT is defined %}
    limit: {{ JH_SINGLEUSER_CPU_LIMIT }}
{% endif %}
{% if JH_PERUSER_STORAGE is defined and JH_PERUSER_STORAGE|bool %}
  initContainers:
    - name: volume-mount-ownership-fix
      image: busybox
      command:
          [
              "sh",
              "-c",
              "id && chown 1000:1000 /home/jovyan && chown 1000:1000 /home/jovyan/shared-readwrite && chown 1000:1000 {{ JH_PERUSER_STORAGE_MOUNT_DIR }} && ls -lhd /home/jovyan",
          ]
      securityContext:
          runAsUser: 0
#      volumeMounts:
#      - name: home
#        mountPath: /home/jovyan
#        subPath: "jovyan"
      # Here so we can chown it appropriately
#      - name: home
#        mountPath: /home/jovyan/shared-readwrite
#        subPath: _shared
#      - name: {{ JH_PERUSER_STORAGE_PV_NAME }}
#        mountPath: {{ JH_PERUSER_STORAGE_MOUNT_DIR }}
#  storage:
#    extraVolumes:
#    - name: "{{ JH_PERUSER_STORAGE_PV_NAME }}"
#      persistentVolumeClaim:
#        claimName: '{{ JH_PERUSER_STORAGE_PVC_NAME }}-{{ ansible_user }}'
#    extraVolumeMounts:
#    - name: "{{ JH_PERUSER_STORAGE_PV_NAME }}"
#      mountPath: {{ JH_PERUSER_STORAGE_MOUNT_DIR }}
  extraContainers:
    - name: postgres
      image: postgres:14.5 # use the latest version available at https://hub.docker.com/_/postgres/tags
      args:
        # Listen only on localhost, rather than on all interfaces
        # This allows us to use passwordless login, as only the user notebook container can access this
        - -c
        - listen_addresses=127.0.0.1
      resources:
        limits:
          # Best effort only. No more than 1 CPU, and if postgres uses more than {{ JH_PERUSER_STORAGE_MEMORY_LIMIT }}, restart it
          memory: {{ JH_PERUSER_STORAGE_MEMORY_LIMIT }}
          cpu: {{ JH_PERUSER_STORAGE_CPU_LIMIT }}
        requests:
          # If we don't set requests, k8s sets requests == limits!
          # So we set something tiny
          memory: 64Mi
          cpu: 0.01
      env:
      # Configured using the env vars documented in https://hub.docker.com/_/postgres/
      # Postgres is only listening on localhost, so we can trust all connections that come to it
      - name: POSTGRES_HOST_AUTH_METHOD
        value: "trust"
      - name: POSTGRES_USER
        value: "jovyan"
      securityContext:
        runAsUser: 1000
#      volumeMounts:
      # Mount the user homedirectory in the postgres db container as well, so postgres commands
      # that load data into the db from disk work
#      - name: home
#        mountPath: /home/jovyan
#        subPath: "jovyan"
#      - name: {{ JH_PERUSER_STORAGE_PV_NAME }}
#        mountPath: {{ JH_PERUSER_STORAGE_MOUNT_DIR }}
{% endif %}
{% if (JH_SHARED_STORAGE_ENABLE is defined and JH_SHARED_STORAGE_ENABLE|bool) or (IRODS_CSI_DRIVER_ENABLE is defined and IRODS_CSI_DRIVER_ENABLE|bool) %}
  storage:
    extraVolumes:
{% if JH_SHARED_STORAGE_ENABLE is defined and JH_SHARED_STORAGE_ENABLE|bool %}
    - name: "{{ JH_SHARED_STORAGE_PV_NAME }}"
      persistentVolumeClaim:
        claimName: "{{ JH_SHARED_STORAGE_PVC_NAME }}"
{% endif %}
{% if IRODS_CSI_DRIVER_ENABLE is defined and IRODS_CSI_DRIVER_ENABLE|bool %}
    - name: "{{ IRODS_CSI_DRIVER_PV_NAME }}"
      persistentVolumeClaim:
        claimName: "{{ IRODS_CSI_DRIVER_PVC_NAME }}"
{% endif %}
    extraVolumeMounts:
{% if JH_SHARED_STORAGE_ENABLE is defined and JH_SHARED_STORAGE_ENABLE|bool %}
    - name: "{{ JH_SHARED_STORAGE_PV_NAME }}"
      mountPath: {{ JH_SHARED_STORAGE_MOUNT_DIR }}
{% endif %}
{% if IRODS_CSI_DRIVER_ENABLE is defined and IRODS_CSI_DRIVER_ENABLE|bool %}
    - name: "{{ IRODS_CSI_DRIVER_PV_NAME }}"
      mountPath: {{ IRODS_CSI_DRIVER_MOUNT_DIR }}
{% endif %}
{% endif %}
{% if JH_SINGLEUSER_GPU_ENABLE is defined and JH_SINGLEUSER_GPU_ENABLE|bool %}
  profileList:
    - display_name: "GPU Server"
      description: "Spawns a notebook server with access to a GPU"
      kubespawner_override:
        extra_resource_limits:
          nvidia.com/gpu: "1"
{% endif %}

# uncomment only if debugging container issues
cull:
  enabled: false
proxy:
{% if JH_INGRESS_ENABLED is defined and JH_INGRESS_ENABLED|bool %}
  service:
    type: ClusterIP
{% endif %}
  chp:
    resources:
      requests:
        # 0m - 1000m
        cpu: 1000m
        # 100Mi - 600Mi
        memory: 500Mi

{% if JH_INGRESS_ENABLED is defined and JH_INGRESS_ENABLED|bool %}
ingress:
  enabled: true
  annotations:
{% if JH_INGRESS_CLASS == "nginx" %}
    nginx.ingress.kubernetes.io/proxy-body-size: "{{ JH_INGRESS_BODY_SIZE }}"
{% endif %}
    kubernetes.io/ingress.class: "{{ JH_INGRESS_CLASS }}"
{% if JH_INGRESS_HOSTNAME is defined %}
  hosts:
  - {{ JH_INGRESS_HOSTNAME }}
{% endif %}
{% endif %}

prePuller:
  hook:
    enabled: {{ JH_PREPULL_IMAGES }}
